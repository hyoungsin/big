{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dVWccam7ItLIFoeSKmBFnA7H6KWdwOaW",
      "authorship_tag": "ABX9TyMumZQt/sHsW/8E/d5tDlnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyoungsin/big/blob/main/Titanic(BIG).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ver.1 (val:0.7593,test : 0.7727)\n",
        " - 1) 변수 : 'Pclass', 'Sex',\"Age\",'SibSp', 'Parch','Fare','Cabin','Embarked'\n",
        " - 2) 수치형 결측치처리 mean\n",
        " - 3) 수치형 결측치러리 : RobustScaler\n",
        " - 4) 문자형 수치형 변환 : LabelEncoder\n",
        " - 5) Train/val split : train_tes_split\n",
        " - 6) 적용 모델 : RandomForestClassifier"
      ],
      "metadata": {
        "id": "FKtMewTSKQix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Dataset구성\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from os.path import join\n",
        "ROOT_PATH = '/content/drive/MyDrive/경진대회/Kaggle/Kaggle_Titanic'\n",
        "\n",
        "train = pd.read_csv(join(ROOT_PATH,'train.csv'))\n",
        "X_test = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "\n",
        "X_train = train.drop('Survived',axis=1)\n",
        "X_train = X_train[['Pclass', 'Sex',\"Age\",'SibSp', 'Parch','Fare','Cabin','Embarked']]\n",
        "X_test = X_test[['Pclass', 'Sex',\"Age\",'SibSp', 'Parch','Fare','Cabin','Embarked']]\n",
        "y_train = train['Survived']\n",
        "X_train.nunique()\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#2.train/test merge, 수치형,범주형 분리\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "num_cols= list(train.select_dtypes(exclude=object).columns) #수치형 컬럼명 추출\n",
        "cat_cols = list(train.select_dtypes(include=object).columns) #명목형 컬럼명 추출\n",
        "\n",
        "#3 결측치 처리 (iterative_imputer)\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "imputer = IterativeImputer(random_state=1003)\n",
        "train[num_cols] = imputer.fit_transform(train[num_cols])\n",
        "\n",
        "#3 결측치 처리 (mean)\n",
        "train[num_cols] = train[num_cols].fillna(train[num_cols])\n",
        "\n",
        "# 4.수치형 Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#4.수치형 Scaling\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#5.문자형 labelencoding \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    train[col] = encoder.fit_transform(train[col])\n",
        "\n",
        "train.isnull().sum()\n",
        "# train.info()\n",
        "\n",
        "#6.train/test split \n",
        "X_train = train[:891]\n",
        "X_test = train[891:]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#7.train,valid 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,\n",
        "                                               test_size = 0.3,\n",
        "                                              random_state=1003)\n",
        "print(X_train.shape,X_val.shape,X_test.shape,y_train.shape,y_val.shape)\n",
        "\n",
        "#8.model fit \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(max_depth = 3,\n",
        "          n_estimators = 300,\n",
        "         random_state=1003)\n",
        "model.fit(X_train,y_train)\n",
        "pred_train = model.predict(X_val)\n",
        "\n",
        "#9.val pred 평가 \n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(round(roc_auc_score(y_val,pred_train),4))\n",
        " \n",
        "#10.예측값 생성\n",
        "pred_test= model.predict(X_test)\n",
        "submit = pd.read_csv(join(ROOT_PATH,'test.csv')) #file오류를 피하기 위해 submission.csv사용 추천 \n",
        "output = pd.DataFrame({'PassengerId': submit.PassengerId, 'Survived': pred_test})\n",
        "output.to_csv('BIG_submission_v1.csv', index=False)\n",
        "pd.read_csv('BIG_submission_v1.csv')['Survived'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvoXYfjWSdqp",
        "outputId": "a2825bb6-44ff-4501-83d1-62feac8d8518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 8) (418, 8) (891,)\n",
            "(891, 8) (418, 8) (891,)\n",
            "(623, 8) (268, 8) (418, 8) (623,) (268,)\n",
            "0.7593\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    319\n",
              "1     99\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6SSJNja-KSE",
        "outputId": "2ad8ffdc-a15b-46b5-d5d5-3c27095a159a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ver.2 (val:0.7711,test:0.7680)\n",
        "- 1) 변수 : \"Pclass\", \"Sex\", \"SibSp\", \"Parch\"\n",
        "- 2) 수치형 결측치처리 mean\n",
        "- 3) 수치형 결측치러리 : RobustScaler\n",
        "- 4) 문자형 수치형 변환 : LabelEncoder\n",
        "- 5) Train/val split : train_tes_split\n",
        "- 6) 적용 모델 : RandomForestClassifier"
      ],
      "metadata": {
        "id": "Db-A-Pl5JFz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Dataset구성\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from os.path import join\n",
        "ROOT_PATH = '/content/drive/MyDrive/경진대회/Kaggle/Kaggle_Titanic'\n",
        "\n",
        "train = pd.read_csv(join(ROOT_PATH,'train.csv'))\n",
        "X_test = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "\n",
        "X_train = train.drop('Survived',axis=1)\n",
        "X_train = X_train[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]]\n",
        "X_test = X_test[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]]\n",
        "y_train = train['Survived']\n",
        "X_train.nunique()\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#2.train/test merge, 수치형,범주형 분리\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "num_cols= list(train.select_dtypes(exclude=object).columns) #수치형 컬럼명 추출\n",
        "cat_cols = list(train.select_dtypes(include=object).columns) #명목형 컬럼명 추출\n",
        "\n",
        "# #3 결측치 처리 (iterative_imputer)\n",
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from sklearn.impute import IterativeImputer\n",
        "# imputer = IterativeImputer(random_state=1003)\n",
        "# train[num_cols] = imputer.fit_transform(train[num_cols])\n",
        "\n",
        "#3 결측치 처리 (mean)\n",
        "train[num_cols] = train[num_cols].fillna(train[num_cols])\n",
        "\n",
        "#4.수치형 Scaling\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#4.수치형 Scaling\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#5.문자형 labelencoding \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    train[col] = encoder.fit_transform(train[col])\n",
        "\n",
        "train.isnull().sum()\n",
        "# train.info()\n",
        "\n",
        "#6.train/test split \n",
        "X_train = train[:891]\n",
        "X_test = train[891:]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#7.train,valid 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,\n",
        "                                               test_size = 0.3,\n",
        "                                              random_state=1003)\n",
        "print(X_train.shape,X_val.shape,X_test.shape,y_train.shape,y_val.shape)\n",
        "\n",
        "#8.model fit \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(max_depth = 3,\n",
        "          n_estimators = 300,\n",
        "         random_state=1003)\n",
        "model.fit(X_train,y_train)\n",
        "pred_train = model.predict(X_val)\n",
        "\n",
        "#9.val pred 평가 \n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(round(roc_auc_score(y_val,pred_train),4))\n",
        "\n",
        "#10.예측값 생성\n",
        "pred_test= model.predict(X_test)\n",
        "submit = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "output = pd.DataFrame({'PassengerId': submit.PassengerId, 'Survived': pred_test})\n",
        "output.to_csv('BIG_submission_v2.csv', index=False)\n",
        "pd.read_csv('BIG_submission_v2.csv')['Survived'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOSeU0rAR6dJ",
        "outputId": "bd6ed7b8-7950-40f6-f92c-72f34a1c7f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 4) (418, 4) (891,)\n",
            "(891, 4) (418, 4) (891,)\n",
            "(623, 4) (268, 4) (418, 4) (623,) (268,)\n",
            "0.7711\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    287\n",
              "1    131\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ver.3 (val:0.7812,test:0.7584)\n",
        "- 1) 변수 : \"Pclass\", \"Sex\", \"SibSp\", \"Parch\" + Age (Binning)\n",
        "- 2) 수치형 결측치처리 iterative_imputer\n",
        "- 3) 수치형 결측치러리 : RobustScaler\n",
        "- 4) 문자형 수치형 변환 : LabelEncoder\n",
        "- 5) Train/val split : train_tes_split\n",
        "- 6) 적용 모델 : XGBClassifier"
      ],
      "metadata": {
        "id": "CjsmncHMR9mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Dataset구성\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from os.path import join\n",
        "ROOT_PATH = '/content/drive/MyDrive/경진대회/Kaggle/Kaggle_Titanic'\n",
        "\n",
        "X_train = pd.read_csv(join(ROOT_PATH,'train.csv'))\n",
        "X_test = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "\n",
        "#2.Aging cat생성 (결측치제거 & cat생성함수 작성)\n",
        "from sklearn.experimental import enable_iterative_imputer #실험 대상, impputer player 가동\n",
        "from sklearn.impute import IterativeImputer #iterativeimpute import \n",
        "\n",
        "imputer = IterativeImputer(random_state=42)\n",
        "X_train['Age'] = imputer.fit_transform(X_train[['Age']]) #train data 결측치 채움 \n",
        "X_test['Age']  = imputer.transform(X_test[['Age']])#test data 결측치 채움\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "train.shape\n",
        "print(X_train.shape,X_test.shape)\n",
        "\n",
        "temp=list(range(train.shape[0]))\n",
        "def new_col_creating(df): #a1.loc[:,'Age_cat'] = 1\n",
        "    for i in range(df.shape[0]): #1309까지 indexing을 함 (0~1308)\n",
        "        if df.iloc[i]['Age']< 10: #해당행의 Age컬럼이 10미만일 경우 1로 반환 \n",
        "            temp[i] = 1\n",
        "        elif (df.iloc[i]['Age']>= 10) & (df.iloc[i]['Age']< 20):\n",
        "            temp[i] = 2\n",
        "        elif (df.iloc[i]['Age']>= 10) & (df.iloc[i]['Age']< 20):\n",
        "            temp[i] = 3     \n",
        "        elif (df.iloc[i]['Age']>= 20) & (df.iloc[i]['Age']< 30):\n",
        "            temp[i] = 4      \n",
        "        elif (df.iloc[i]['Age']>= 30) & (df.iloc[i]['Age']< 40):\n",
        "            temp[i] = 5\n",
        "        elif (df.iloc[i]['Age']>= 40) & (df.iloc[i]['Age']< 50):\n",
        "            temp[i] = 6     \n",
        "        elif (df.iloc[i]['Age']>= 50) & (df.iloc[i]['Age']< 60):\n",
        "            temp[i] = 7   \n",
        "        elif (df.iloc[i]['Age']>= 60):\n",
        "            temp[i] = 8\n",
        "        else:\n",
        "            temp[i] = np.nan\n",
        "            \n",
        "    return temp\n",
        " \n",
        "train['Age_cat']=new_col_creating(train) #함수 활용 Age_cat 컬럼 생성 \n",
        "train['Age_cat'].value_counts()\n",
        "train.shape\n",
        "\n",
        "#3.Dataset재구성\n",
        "X_train = train.iloc[:891]\n",
        "X_test = train.iloc[891:]\n",
        "y_train = X_train['Survived']\n",
        "X_train = X_train.drop('Survived',axis=1).copy()\n",
        "X_test = X_test.drop('Survived',axis=1).copy()\n",
        "X_train = X_train[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",'Age_cat']]\n",
        "X_test = X_test[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",'Age_cat']]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#4.train/test merge, 수치형,범주형 분리\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "num_cols= list(train.select_dtypes(exclude=object).columns) #수치형 컬럼명 추출\n",
        "cat_cols = list(train.select_dtypes(include=object).columns) #명목형 컬럼명 추출\n",
        "\n",
        "# #5.수치형 Scaling\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#5.문자형 labelencoding \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    train[col] = encoder.fit_transform(train[col])\n",
        "    \n",
        "#6.train/test split \n",
        "X_train = train[:891]\n",
        "X_test = train[891:]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "#7.train,valid 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,\n",
        "                                               test_size = 0.3,\n",
        "                                              random_state=1003)\n",
        "print(X_train.shape,X_val.shape,X_test.shape,y_train.shape,y_val.shape)\n",
        "\n",
        "#8.model fit(XGB : 0.79)\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(max_depth = 7,\n",
        "          n_estimators = 2800,\n",
        "         random_state=1003)\n",
        "model.fit(X_train,y_train)\n",
        "pred_train = model.predict(X_val)\n",
        "\n",
        "#8.model fit (랜덤포레스트 : 0.77)\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# model = RandomForestClassifier(max_depth = 7,\n",
        "#           n_estimators = 2800,\n",
        "#          random_state=1003)\n",
        "# model.fit(X_train,y_train)\n",
        "# pred_train = model.predict(X_val)\n",
        "\n",
        "#9.val pred 평가 \n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(round(roc_auc_score(y_val,pred_train),4))\n",
        "\n",
        "#10.예측값 생성\n",
        "pred_test= model.predict(X_test)\n",
        "submit = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "output = pd.DataFrame({'PassengerId': submit.PassengerId, 'Survived': pred_test})\n",
        "output.to_csv('BIG_submission_v3.csv', index=False)\n",
        "pd.read_csv('BIG_submission_v3.csv')['Survived'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ4wFo2oR-Hi",
        "outputId": "f8d5d48d-b39b-4ebd-b250-55a7518ec70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 12) (418, 11)\n",
            "(891, 5) (418, 5) (891,)\n",
            "(891, 5) (418, 5) (891,)\n",
            "(623, 5) (268, 5) (418, 5) (623,) (268,)\n",
            "0.7812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    267\n",
              "1.0    151\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ver.4 (val:0.7800,test:0.7464)\n",
        "- 1) 변수 : \"Pclass\", \"Sex\", \"SibSp\", \"Parch\" + Age (Binning)\n",
        "- 2) 수치형 결측치처리 iterative_imputer\n",
        "- 3) 수치형 결측치러리 : RobustScaler\n",
        "- 4) 문자형 수치형 변환 : LabelEncoder\n",
        "- 5) Train/val split : CV\n",
        "- 6) 적용 모델 : XGBClassifier"
      ],
      "metadata": {
        "id": "FZw8Dlo2fADd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Dataset구성\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from os.path import join\n",
        "ROOT_PATH = '/content/drive/MyDrive/경진대회/Kaggle/Kaggle_Titanic'\n",
        "\n",
        "X_train = pd.read_csv(join(ROOT_PATH,'train.csv'))\n",
        "X_test = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "\n",
        "#2.Aging cat생성 (결측치제거 & cat생성함수 작성)\n",
        "from sklearn.experimental import enable_iterative_imputer #실험 대상, impputer player 가동\n",
        "from sklearn.impute import IterativeImputer #iterativeimpute import \n",
        "\n",
        "imputer = IterativeImputer(random_state=42)\n",
        "X_train['Age'] = imputer.fit_transform(X_train[['Age']]) #train data 결측치 채움 \n",
        "X_test['Age']  = imputer.transform(X_test[['Age']])#test data 결측치 채움\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "print(X_train.shape,X_test.shape)\n",
        "\n",
        "temp=list(range(train.shape[0]))\n",
        "def new_col_creating(df): #a1.loc[:,'Age_cat'] = 1\n",
        "    for i in range(df.shape[0]): #1309까지 indexing을 함 (0~1308)\n",
        "        if df.iloc[i]['Age']< 10: #해당행의 Age컬럼이 10미만일 경우 1로 반환 \n",
        "            temp[i] = 1\n",
        "        elif (df.iloc[i]['Age']>= 10) & (df.iloc[i]['Age']< 20):#해당행의 Age컬럼이 10이상 20미만일 경우 2로 반환 \n",
        "            temp[i] = 2\n",
        "        elif (df.iloc[i]['Age']>= 10) & (df.iloc[i]['Age']< 20):\n",
        "            temp[i] = 3     \n",
        "        elif (df.iloc[i]['Age']>= 20) & (df.iloc[i]['Age']< 30):\n",
        "            temp[i] = 4      \n",
        "        elif (df.iloc[i]['Age']>= 30) & (df.iloc[i]['Age']< 40):\n",
        "            temp[i] = 5\n",
        "        elif (df.iloc[i]['Age']>= 40) & (df.iloc[i]['Age']< 50):\n",
        "            temp[i] = 6     \n",
        "        elif (df.iloc[i]['Age']>= 50) & (df.iloc[i]['Age']< 60):\n",
        "            temp[i] = 7   \n",
        "        elif (df.iloc[i]['Age']>= 60):\n",
        "            temp[i] = 8\n",
        "        else:\n",
        "            temp[i] = np.nan #해당행의 Age컬럼이 n.a일 경우 결측치로 반환 \n",
        "            \n",
        "    return temp\n",
        " \n",
        "train['Age_cat']=new_col_creating(train) #함수 활용 Age_cat 컬럼 및 컬럼값 순차적으로 반복 생성 (1~8)\n",
        "train['Age_cat'].value_counts() #입력값 점검\n",
        "\n",
        "#3.Dataset재구성\n",
        "X_train = train.iloc[:891]\n",
        "X_test = train.iloc[891:]\n",
        "y_train = X_train['Survived']\n",
        "id = X_test['PassengerId']\n",
        "\n",
        "X_train = X_train.drop('Survived',axis=1).copy()\n",
        "X_test = X_test.drop('Survived',axis=1).copy()\n",
        "X_train = X_train[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",'Age_cat']]\n",
        "X_test = X_test[[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",'Age_cat']]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "\n",
        "#4.train/test merge, 수치형,범주형 분리\n",
        "train = pd.concat([X_train,X_test],axis=0)\n",
        "num_cols= list(train.select_dtypes(exclude=object).columns) #수치형 컬럼명 추출\n",
        "cat_cols = list(train.select_dtypes(include=object).columns) #명목형 컬럼명 추출\n",
        "\n",
        "#5.수치형 Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "\n",
        "#5.문자형 labelencoding \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    train[col] = encoder.fit_transform(train[col])\n",
        "    \n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "print(train.shape)\n",
        "\n",
        "#6.train/test split \n",
        "X_train = train[:891]\n",
        "X_test = train[891:]\n",
        "print(X_train.shape,X_test.shape,y_train.shape)\n",
        "\n",
        "data = X_train\n",
        "label = np.array(y_train)\n",
        "data.shape,label.shape\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold #label의 분포를 split별 동일하게 구성 \n",
        "val_scores = list() # 빈list만들기\n",
        "spliter = StratifiedKFold(n_splits=5, shuffle=True, random_state=2022) #5 fold만들기,섞기 \n",
        "\n",
        "for i, (trn_idx, val_idx) in enumerate(spliter.split(data, label)): #id형태로 데이터셋 추출하기 (label은 넘파이형태로)\n",
        "    X_train, y_train = data.iloc[trn_idx], label[trn_idx] #X_train,y_train정의 (변수명 중복불가, data / label --> X_train,y_train)\n",
        "    X_val, y_val = data.iloc[val_idx], label[val_idx] #X_val,y_valid정의\n",
        "\n",
        "    #8.model fit(XGB : 0.79)\n",
        "    from xgboost import XGBClassifier\n",
        "    from sklearn.metrics  import roc_auc_score\n",
        "    model = XGBClassifier(max_depth = 7,\n",
        "              n_estimators = 2800,\n",
        "              random_state=1003)\n",
        "    model.fit(X_train,y_train)\n",
        "    pred_train = model.predict(X_val)\n",
        "    \n",
        "    # 훈련, 검증 데이터 f1_score 확인\n",
        "    roc_train = roc_auc_score(y_train, model.predict(X_train)) #train의 roc_auc_score 구하기 \n",
        "    roc_val = roc_auc_score(y_val, model.predict(X_val)) #valid의 roc_auc_score 구하기\n",
        "    print('{} Fold, train roc_score : {:.4f}, validation roc_score : {:.4f}'.format(i, roc_train,roc_val)) #5번i 반복결과 도출 \n",
        "\n",
        "    val_scores.append(roc_val) # split할때마다 roc_val 리스트에 포함시키기 \n",
        "\n",
        "    # 교차 검증 f1_score 평균 계산하기\n",
        "    print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores))) #리스트값을 평균내기\n",
        "    \n",
        "#10.예측값 생성\n",
        "pred_test= model.predict(X_test)\n",
        "submit = pd.read_csv(join(ROOT_PATH,'test.csv'))\n",
        "output = pd.DataFrame({'PassengerId': submit.PassengerId, 'Survived': pred_test})\n",
        "output.to_csv('BIG_submission_v4(error)).csv', index=False)\n",
        "pd.read_csv('BIG_submission_v4(error)).csv')['Survived'].value_counts()"
      ],
      "metadata": {
        "id": "9873ntRzqclh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9123b659-f97a-45b6-a219-7aa5ac057be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 12) (418, 11)\n",
            "(891, 5) (418, 5) (891,)\n",
            "(891, 5) (418, 5) (891,)\n",
            "(1309, 5)\n",
            "(891, 5) (418, 5) (891,)\n",
            "0 Fold, train roc_score : 0.8461, validation roc_score : 0.7616\n",
            "Cross Validation Score : 0.7616\n",
            "1 Fold, train roc_score : 0.8358, validation roc_score : 0.8131\n",
            "Cross Validation Score : 0.7873\n",
            "2 Fold, train roc_score : 0.8602, validation roc_score : 0.7389\n",
            "Cross Validation Score : 0.7712\n",
            "3 Fold, train roc_score : 0.8438, validation roc_score : 0.7519\n",
            "Cross Validation Score : 0.7664\n",
            "4 Fold, train roc_score : 0.8389, validation roc_score : 0.8343\n",
            "Cross Validation Score : 0.7800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    264\n",
              "1.0    154\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soRuZlzXKVPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
